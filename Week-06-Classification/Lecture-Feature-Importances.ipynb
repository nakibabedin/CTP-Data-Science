{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This lecture was assisted by ChatGPT, and it fudged up bad.  \n",
    "## I (\"I\" = Zach, FYI...) fixed it, but it took me a bit of time to even realize it fudged up.\n",
    "Most of the code, and most of the interpertation was generated by ChatGTP.  I tried to leave the exact input and output to what I asked it. However....... \n",
    "\n",
    "### **You cannot blindly follow what ChatGPT does** \n",
    "* ChatGPT made a huge mistake in the example below (I left it in to see if yall can see it too).  \n",
    "* Without knowing what it was doing, would LOOK fine, but very very wrong.  \n",
    "* Gotta be careful when you use ChatGPT.  When it is wrong, it sounds very right. \n",
    "\n",
    "Here is a story of a lawyer that did blindly follow ChatGPT and it made up mad fake stuff, he asked it if it was fake or not and it said, nahh they real.  He used them in court and got in crazy trouble. \n",
    "\n",
    "* Forbes - [Lawyer Used ChatGPT In Courtâ€”And Cited Fake Cases. A Judge Is Considering Sanctions](https://www.forbes.com/sites/mollybohannon/2023/06/08/lawyer-used-chatgpt-in-court-and-cited-fake-cases-a-judge-is-considering-sanctions/?sh=15e02fe47c7f)\n",
    "* NYT - [The ChatGPT Lawyer Explains Himself](https://www.nytimes.com/2023/06/08/nyregion/lawyer-chatgpt-sanctions.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries \n",
    "\n",
    "# Pandas and numpy for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seaborn / matplotlib for visualization \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Helper function to split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This is our Logit model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Helper fuctions to evaluate our model.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only using AGE as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load and Inspect\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Inspect, we did this in the previous lecture file. \n",
    "\n",
    "# Select and Engineer. \n",
    "features = ['age', 'sex_male']\n",
    "target = 'survived'\n",
    "\n",
    "# Drop rows with missing target or missing important features\n",
    "df.dropna(subset=['survived', 'age', 'fare'], inplace=True)\n",
    "\n",
    "# Convert categorical variables to dummy variables (one-hot encoding)\n",
    "df = pd.get_dummies(df, columns=['sex', 'pclass'], dtype=int, drop_first=True)\n",
    "\n",
    "# Define Features and Target\n",
    "X = df[features]  \n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# Split the Dataset into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Adding a constant term for intercept \n",
    "X_train_sm = sm.add_constant(X_train)   \n",
    "\n",
    "\n",
    "# Fit the Logistic Regression Model using Statsmodels\n",
    "logit_model = sm.Logit(endog=y_train, exog=X_train_sm)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Make Predictions on the Test Set\n",
    "X_test_sm = sm.add_constant(X_test)  # Adding constant to test data\n",
    "y_pred_prob = result.predict(X_test_sm)  # Predicting probabilities\n",
    "y_pred = np.where(y_pred_prob > 0.5, 1, 0)  # Convert probabilities to binary predictions (using 0.5 as threshold)\n",
    "\n",
    "## EVALUATE \n",
    "\n",
    "# ACCURACY\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "# F1 ACCURACY\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score: %f\" % f1)\n",
    "\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Greens', fmt='g')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.xlabel('Model Prediction');\n",
    "\n",
    "\n",
    "\n",
    "# Add to our dataframe to interprept \n",
    "X_test_sm['y_pred_proba'] = y_pred_prob\n",
    "X_test_sm['y_pred'] = y_pred\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n",
    "\n",
    "X_test_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### THIS FUNCTION WAS FULLLY WRITTEN BY GPT\n",
    "\n",
    "def interpret_statsmodels_logit(result):\n",
    "    \"\"\"\n",
    "    Converts the coefficients of a statsmodels Logit object (log-odds) into odds ratios and percentage changes.\n",
    "\n",
    "    Parameters:\n",
    "    result (statsmodels object): The fitted statsmodels logistic regression model.\n",
    "\n",
    "    Returns:\n",
    "    None: Prints the log-odds, odds ratio, and percentage change for each coefficient.\n",
    "    \"\"\"\n",
    "    # Extract the coefficients from the statsmodels results object\n",
    "    coefficients = result.params\n",
    "\n",
    "    # Loop through each coefficient and interpret it\n",
    "    print(\"Interpretation of Logistic Regression Coefficients:\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    for feature, log_odds in coefficients.items():\n",
    "        # Convert log-odds to odds ratio\n",
    "        odds_ratio = np.exp(log_odds)\n",
    "\n",
    "        # Convert odds ratio to percentage change\n",
    "        percentage_change = (odds_ratio - 1) * 100\n",
    "\n",
    "        # Print the interpretation\n",
    "        print(f\"Feature: {feature}\")\n",
    "        print(f\"  Log-Odds: {log_odds:.4f}\")\n",
    "        print(f\"  Odds Ratio: {odds_ratio:.4f}\")\n",
    "        print(f\"  Percentage Change in Odds: {percentage_change:.2f}%\")\n",
    "        print(\"\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming `result` is your fitted statsmodels logistic regression object from the earlier code\n",
    "interpret_statsmodels_logit(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Step 1: Load the Titanic Dataset\n",
    "# Assuming you have the dataset as a CSV file named 'titanic.csv'.\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Drop rows with missing target or missing important features\n",
    "df.dropna(subset=['survived', 'age', 'fare'], inplace=True)\n",
    "\n",
    "# Convert categorical variables to dummy variables (one-hot encoding)\n",
    "df = pd.get_dummies(df, columns=['sex', 'pclass'], dtype=int, drop_first=True)\n",
    "\n",
    "\n",
    "features = ['age', 'fare', 'sex_male', 'pclass_2', 'pclass_3']\n",
    "target = 'survived'\n",
    "\n",
    "# Step 4: Define Features and Target\n",
    "X = df[features]  \n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# # Step 6: Split the Dataset into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 7: Fit the Logistic Regression Model using Statsmodels\n",
    "X_train_sm = sm.add_constant(X_train)  # Adding a constant term for intercept\n",
    "logit_model = sm.Logit(endog=y_train, exog=X_train_sm)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n",
    "\n",
    "# Make Predictions on the Test Set\n",
    "X_test_sm = sm.add_constant(X_test)  # Adding constant to test data\n",
    "y_pred_prob = result.predict(X_test_sm)  # Predicting probabilities\n",
    "y_pred = np.where(y_pred_prob > 0.5, 1, 0)  # Convert probabilities to binary predictions (using 0.5 as threshold)\n",
    "\n",
    "## EVALUATE \n",
    "\n",
    "# ACCURACY\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "# F1 ACCURACY\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score: %f\" % f1)\n",
    "\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Greens', fmt='g')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.xlabel('Model Prediction');\n",
    "\n",
    "\n",
    "\n",
    "# Add to our dataframe to interprept \n",
    "X_test_sm['y_pred_proba'] = y_pred_prob\n",
    "X_test_sm['y_pred'] = y_pred\n",
    "X_test_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interpret_statsmodels_logit(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
